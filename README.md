ğŸ¤– RAG Chat Interface
Retrieval-Augmented Generation com interface web moderna usando Streamlit
Interface intuitiva para fazer perguntas sobre documentos PDF ou conteÃºdo web, utilizando modelos de IA locais (Ollama) ou na nuvem (OpenAI).

ğŸš€ Como executar
bash# Instalar dependÃªncias
pip install -r requirements.txt

# Configurar variÃ¡veis de ambiente
cp .env.example .env
# Edite o .env com suas configuraÃ§Ãµes

# Executar aplicaÃ§Ã£o web
streamlit run main.py

ğŸ“ Estrutura do projeto
ğŸ“¦ rag-chat-interface/
â”œâ”€â”€ ğŸ“„ main.py                     # Interface Streamlit - App principal
â”œâ”€â”€ ğŸ§  rag.py                      # Motor RAG - Processamento de perguntas
â”œâ”€â”€ ğŸ—ƒï¸ vectordb.py                 # Banco vetorial - FAISS + embeddings
â”œâ”€â”€ ğŸ“‹ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ ğŸ”§ .env.example               # Template de configuraÃ§Ã£o
â”œâ”€â”€ ğŸ“– README.md                  # DocumentaÃ§Ã£o do projeto
â”œâ”€â”€ ğŸ“‚ .github/
â”‚   â””â”€â”€ ğŸ“ copilot-instructions.md # InstruÃ§Ãµes para GitHub Copilot
â””â”€â”€ ğŸ“‚ __pycache__/               # Cache Python (auto-gerado)

âœ¨ Funcionalidades
ğŸ  Ollama Local

ğŸ¤– Modelos executados localmente
ğŸ“„ Processamento de PDFs
ğŸŒ AnÃ¡lise de conteÃºdo web
ğŸ”’ Privacidade total dos dados

â˜ï¸ OpenAI Cloud

ğŸš€ GPT-4 via API
ğŸ“Š Processamento otimizado
ğŸŒ Acesso global
âš¡ Respostas rÃ¡pidas

ğŸ¯ Recursos TÃ©cnicos

Vector Database: FAISS para busca semÃ¢ntica
Text Splitting: Chunks inteligentes para melhor contexto
Dual Processing: Local (Ollama) + Cloud (OpenAI)
File Handling: Upload seguro de PDFs com limpeza automÃ¡tica
Web Scraping: ExtraÃ§Ã£o de conteÃºdo de URLs


ğŸ› ï¸ Tecnologias
ComponenteTecnologiaInterfaceStreamlitLLM LocalOllama (Gemma 12B)LLM CloudOpenAI GPT-4o-miniEmbeddingsOpenAI + Snowflake ArcticVector DBFAISSPDF ParserPyPDFWeb LoaderLangChain WebBase

ğŸ”§ ConfiguraÃ§Ã£o
Arquivo .env
env# OpenAI (para modo nuvem)
OPENAI_API_KEY=sua_chave_aqui

# Ollama (para modo local)
OLLAMA_BASE_URL=http://localhost:11434

# ConfiguraÃ§Ãµes gerais
USER_AGENT=rag-chat-interface
Modelos Ollama
bash# Instalar modelos necessÃ¡rios
ollama pull gemma3:12b
ollama pull snowflake-arctic-embed2:latest

ğŸ® Como usar

Escolha o modo: Ollama (local) ou OpenAI (nuvem)
Selecione a fonte: PDF upload ou URL
FaÃ§a sua pergunta: Digite o que deseja saber
Obtenha respostas: Contextualizadas com o documento

ğŸ’¡ Exemplos de uso

"Resuma os pontos principais deste PDF"
"Quais sÃ£o as conclusÃµes do artigo?"
"Explique o conceito mencionado na pÃ¡gina X"


ğŸ”„ Fluxo de Dados
mermaidgraph TD
    A[ğŸ‘¤ UsuÃ¡rio] --> B[ğŸ–¥ï¸ Interface Streamlit]
    B --> C{ğŸ“ Fonte?}
    
    C -->|PDF| D[ğŸ“„ Upload + Temp File]
    C -->|URL| E[ğŸŒ Web Scraping]
    
    D --> F[ğŸ”¤ Text Splitting]
    E --> F
    
    F --> G[ğŸ§® Embeddings]
    G --> H[ğŸ—ƒï¸ Vector Store FAISS]
    
    H --> I{ğŸ¤– Modelo?}
    I -->|Local| J[ğŸ  Ollama]
    I -->|Cloud| K[â˜ï¸ OpenAI]
    
    J --> L[ğŸ’¬ Resposta]
    K --> L
    
    L --> B
    B --> A

ğŸ§ª Arquitetura RAG
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ğŸ“„ Document   â”‚ -> â”‚  ğŸ”¤ Text Split   â”‚ -> â”‚ ğŸ§® Embeddings  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚
         v                        v                        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ—ƒï¸ Vector Store â”‚ <- â”‚ ğŸ” Similarity    â”‚ <- â”‚ â“ User Query   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    Search        â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
         v                        â”‚                        v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              v              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“ Context      â”‚ -----------> ğŸ¤– LLM ------> â”‚ ğŸ’¬ Answer      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              Model          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“‹ Requisitos

Python: 3.8+
Ollama: Para execuÃ§Ã£o local
OpenAI API: Para modo nuvem
DependÃªncias: Ver requirements.txt


ğŸš§ Desenvolvimento
Estrutura de CÃ³digos

main.py: Interface Streamlit com abas e controles
rag.py: LÃ³gica RAG, templates de prompt e chains
vectordb.py: Carregamento de documentos e criaÃ§Ã£o de embeddings

PadrÃµes utilizados

âœ… SeparaÃ§Ã£o de responsabilidades
âœ… FunÃ§Ãµes modulares reutilizÃ¡veis
âœ… Gerenciamento seguro de arquivos temporÃ¡rios
âœ… Tratamento de diferentes fontes de dados
âœ… Interface responsiva e intuitiva


ğŸ¤ ContribuiÃ§Ã£o
Sinta-se Ã  vontade para contribuir com melhorias, correÃ§Ãµes ou novas funcionalidades!

ğŸ¯ Transforme documentos em conversas inteligentes!
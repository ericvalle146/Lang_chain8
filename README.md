<div align="center">
ğŸš€ Interface RAG Chat
"Onde Documentos Encontram InteligÃªncia"
Transforme documentos estÃ¡ticos em conversas dinÃ¢micas com IA de ponta

ğŸ¯ Demo â€¢ âš¡ InÃ­cio RÃ¡pido â€¢ ğŸ“– DocumentaÃ§Ã£o â€¢ ğŸ¤ Contribuir

</div>
ğŸŒŸ O Que Torna Isso Especial?
<table> <tr> <td width="50%">
ğŸ  Filosofia Local-First
ğŸ”’ Zero Vazamento de Dados - Seus documentos nunca saem da sua mÃ¡quina

ğŸš€ Ultra RÃ¡pido - Modelos Ollama executam localmente

ğŸ’° Custo Zero - Sem custos de API para processamento local

ğŸ›¡ï¸ Privacidade por Design - Controle total dos seus dados

</td> <td width="50%">
â˜ï¸ Poder da Nuvem DisponÃ­vel
ğŸ§  InteligÃªncia GPT-4 - Acesso aos modelos mais avanÃ§ados

ğŸŒ Escala Global - Processe documentos de qualquer lugar

âš¡ Performance Otimizada - InferÃªncia ultra-rÃ¡pida na nuvem

ğŸ”„ Troca Perfeita - Alterne entre local/nuvem instantaneamente

</td> </tr> </table>
ğŸ¯ Demo
mermaid
Copiar
Editar
graph LR
    A[ğŸ“„ Upload PDF] --> B[ğŸ¤– Escolha Modelo IA]
    B --> C[â“ FaÃ§a Pergunta]
    C --> D[ğŸ’¡ Resposta Inteligente]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
De Documento a Insight em 30 Segundos
âš¡ InÃ­cio RÃ¡pido
<details> <summary><b>ğŸ”§ ConfiguraÃ§Ã£o em Um Clique</b></summary>
bash
Copiar
Editar
# ğŸš€ Clone & Configure
git clone <seu-repositorio>
cd rag-chat-interface

# ğŸ“¦ Instalar DependÃªncias
pip install -r requirements.txt

# ğŸ”‘ Configurar Ambiente
cp .env.example .env
# Adicione suas chaves API no .env

# ğŸ¬ Executar AplicaÃ§Ã£o
streamlit run main.py
ğŸ‰ Pronto! Sua interface RAG estÃ¡ online em http://localhost:8501

</details> <details> <summary><b>ğŸ³ Deploy RÃ¡pido com Docker</b></summary>
bash
Copiar
Editar
# ğŸ—ï¸ Build & Execute
docker build -t rag-chat .
docker run -p 8501:8501 rag-chat

# ğŸŒ Acesse em localhost:8501
</details>
ğŸ—ï¸ Arquitetura
mermaid
Copiar
Editar
flowchart TD
    subgraph "ğŸ–¥ï¸ Camada Frontend"
        A[Interface Streamlit] 
        B[Upload de Arquivos]
        C[Interface Chat]
    end
    
    subgraph "ğŸ§  Camada Processamento"
        D[Parser Documentos]
        E[Divisor de Texto]
        F[Motor Embeddings]
    end
    
    subgraph "ğŸ—ƒï¸ Camada Armazenamento"
        G[FAISS Vector DB]
        H[Arquivos TemporÃ¡rios]
    end
    
    subgraph "ğŸ¤– Camada IA"
        I[Ollama Local]
        J[OpenAI Nuvem]
    end
    
    A --> D
    B --> D
    D --> E
    E --> F
    F --> G
    G --> I
    G --> J
    I --> C
    J --> C
ğŸ“ Estrutura do Projeto
graphql
Copiar
Editar
ğŸ“¦ rag-chat-interface/
â”œâ”€â”€ main.py                     # Interface Streamlit
â”œâ”€â”€ rag.py                      # Motor RAG
â”œâ”€â”€ vectordb.py                 # Banco Vetorial
â”œâ”€â”€ requirements.txt            # DependÃªncias
â”œâ”€â”€ .env.example                # ConfiguraÃ§Ã£o de Ambiente
â”œâ”€â”€ README.md                   # DocumentaÃ§Ã£o
â”œâ”€â”€ .gitignore                  # Git Ignore
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ copilot-instructions.md # Diretrizes IA
â””â”€â”€ __pycache__/                # Cache Python
ğŸ® Showcase de Recursos
<table> <tr> <td width="33%">
ğŸ“„ Processamento Inteligente de PDF
ğŸ” Parsing Inteligente

âœ‚ï¸ DivisÃ£o Otimizada

ğŸ·ï¸ PreservaÃ§Ã£o de Metadados

ğŸš€ Processamento em Lote

</td> <td width="33%">
ğŸŒ AnÃ¡lise de ConteÃºdo Web
ğŸ•·ï¸ Scraping Inteligente

ğŸ”— ValidaÃ§Ã£o de URL

ğŸ“Š Filtragem de ConteÃºdo

ğŸ”„ Tempo Real

</td> <td width="33%">
ğŸ§® InteligÃªncia Vetorial
ğŸ¯ Busca SemÃ¢ntica

ğŸ“ PontuaÃ§Ã£o de Similaridade

ğŸ’¾ Armazenamento FAISS

âš¡ Respostas RÃ¡pidas

</td> </tr> </table>
ğŸ› ï¸ Stack TecnolÃ³gica
Categoria	Tecnologia	PropÃ³sito
ğŸ¨ Frontend	Streamlit	Interface Web Interativa
ğŸ§  LLM Local	Ollama	Modelos Locais Privados
â˜ï¸ LLM Nuvem	OpenAI	IA de Nuvem AvanÃ§ada
ğŸ”— Framework	LangChain	Framework de AplicaÃ§Ãµes IA
ğŸ—ƒï¸ Banco Vetorial	FAISS	Busca por Similaridade
ğŸ“„ Parser PDF	PyPDF	Processamento de Documentos
ğŸŒ Web Scraper	WebLoader	ExtraÃ§Ã£o de ConteÃºdo da Web

âš™ï¸ ConfiguraÃ§Ã£o
<details> <summary><b>ğŸ” ConfiguraÃ§Ã£o de Ambiente</b></summary>
env
Copiar
Editar
# ğŸŒŸ ConfiguraÃ§Ã£o OpenAI (Modo Nuvem)
OPENAI_API_KEY=sk-sua-chave-secreta-aqui
OPENAI_MODEL=gpt-4o-mini

# ğŸ  ConfiguraÃ§Ã£o Ollama (Modo Local)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_LLM_MODEL=gemma3:12b
OLLAMA_EMBED_MODEL=snowflake-arctic-embed2:latest

# ğŸŒ ConfiguraÃ§Ãµes Gerais
USER_AGENT=rag-chat-interface/1.0
LOG_LEVEL=INFO
MAX_FILE_SIZE=50MB
</details> <details> <summary><b>ğŸ¤– ConfiguraÃ§Ã£o dos Modelos Ollama</b></summary>
bash
Copiar
Editar
# ğŸ“¥ Baixar Modelos
ollama pull gemma3:12b
ollama pull snowflake-arctic-embed2:latest

# ğŸ” Verificar InstalaÃ§Ã£o
ollama list

# ğŸš€ Iniciar ServiÃ§o
ollama serve
</details>
ğŸ¯ Guia de Uso
ğŸš€ ComeÃ§ando em 3 Passos
1ï¸âƒ£ Escolha Sua IA â€“ Aba Ollama ou OpenAI
2ï¸âƒ£ Envie Seu ConteÃºdo â€“ Upload de PDF ou URL
3ï¸âƒ£ Comece a Conversa â€“ FaÃ§a perguntas e receba respostas

ğŸ’¡ Casos de Uso
<details> <summary><b>ğŸ“š Pesquisa AcadÃªmica</b></summary>
Resumos de seÃ§Ãµes

RevisÃ£o de literatura

InterpretaÃ§Ã£o estatÃ­stica

Esclarecimento de conceitos

</details> <details> <summary><b>ğŸ“‹ InteligÃªncia de NegÃ³cios</b></summary>
AnÃ¡lise de relatÃ³rios

Pesquisa de mercado

Insights estratÃ©gicos

AnÃ¡lise competitiva

</details> <details> <summary><b>ğŸ“– Aprendizado Pessoal</b></summary>
Resumos de livros

GeraÃ§Ã£o de quiz

ExplicaÃ§Ãµes simples

ConexÃ£o entre ideias

</details>
ğŸš€ Recursos AvanÃ§ados
mermaid
Copiar
Editar
mindmap
  root((Recursos RAG))
    Processamento Inteligente
      DivisÃ£o Inteligente
      PreservaÃ§Ã£o Contexto
      ExtraÃ§Ã£o Metadados
    Suporte Multi-Modal
      Documentos PDF
      ConteÃºdo Web
      Arquivos Texto
    Flexibilidade IA
      Modelos Locais
      APIs Nuvem
      Troca de Modelos
    SeguranÃ§a Primeiro
      Limpeza Arquivos Temp
      ProteÃ§Ã£o Privacidade
      Processamento Seguro
ğŸ“Š MÃ©tricas de Performance
MÃ©trica	Local (Ollama)	Nuvem (OpenAI)
ğŸš€ Tempo Resposta	10â€“40 segundos	2â€“5 segundos
ğŸ’° Custo por Query	R$ 0,00	~R$ 0,01
ğŸ”’ NÃ­vel Privacidade	100% Privado	Processamento Nuvem
ğŸ“Š Qualidade da Resposta	5,5/10	9,5/10

ğŸ”§ Desenvolvimento
<details> <summary><b>ğŸ—ï¸ ConfiguraÃ§Ã£o Desenvolvimento Local</b></summary>
bash
Copiar
Editar
git clone <seu-fork>
cd rag-chat-interface

python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

pip install -r requirements.txt
pip install -r requirements-dev.txt

pytest tests/
black .
isort .

streamlit run main.py --server.runOnSave true
</details> <details> <summary><b>ğŸ“ OrganizaÃ§Ã£o do CÃ³digo</b></summary>
python
Copiar
Editar
# main.py - UI
# rag.py - lÃ³gica IA
# vectordb.py - camada vetorial
</details>
ğŸ¤ ContribuiÃ§Ã£o
ğŸŒŸ Adoramos Contribuidores!
<details> <summary><b>ğŸ¯ Como Contribuir</b></summary>
Fork

Nova branch (feature/recurso-incrivel)

Code & teste

Commit (git commit -m 'Adiciona recurso incrÃ­vel')

Push

Pull Request

</details> <details> <summary><b>ğŸ’¡ Ideias de ContribuiÃ§Ã£o</b></summary>
Melhorias UI/UX

Suporte a novos modelos

Dashboard

Suporte multi-idioma

SeguranÃ§a avanÃ§ada

OtimizaÃ§Ã£o para mobile

</details>
ğŸ“œ LicenÃ§a
Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT

ğŸ™ Agradecimentos
ğŸš€ ConstruÃ­do com amor e IA

Transformando a maneira como interagimos com documentos, uma pergunta por vez.